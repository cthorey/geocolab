{% extends "layout.html" %}
{% from 'nav-macro.html' import generatenav as gnav %}

{% block header %}
{% endblock %}

{% block early_js %}
{% endblock %}

{% block nav %}
    {{gnav("","","","active")}}
{% endblock %}

{% block content %}
    <div class="container">
        <div class="container">
            <h2 class="text-center"> FAQ</h2>
            <hr class="featurette-divider">
            <h4> Why are these apps useful ? </h4>
            <p class="lead"> <small> They spare your time by finding
                relevant contributions for you, organizing your week
                and finding some colleagues you could potentially work
                with.</small>
            </p>
            
            <h4> How does it work ? </h4>
            <p class="lead"> <small> Both apps are built on top of the
            same recommendation engine which find relevant abstracts
            for you given the query or the abstract you specify.</small>
            </p>
            
            <h4> I mean, the recommendation engine ? </h4>
            <p class="lead"> <small> It builds a representation of
                each abstract in a high-dimensional space (500 to be
                precise) and computes the similarity of your request
                against all the contributions.  The engine just
                returns the closest ones (in term of this
                similarity measure) to your request, be it some
                keywords or an abstract.</small>
            </p>
            
            <h4> A representation ? </h4>
            <p class="lead"> <small> Yes, it associates to each
            abstract a 500-dimensional vector in a 500-dimensional
            space.</small>
            </p>
            
            <h4> Based on what ? </h4>
            <p class="lead"> <small> Essentially, the <a href="https://en.wikipedia.org/wiki/Bag-of-words_model">Bag Of Word
                model</a>. Long story short, it first passes through all
                the abstracts and builds a dictionary, let's call it a
                corpus dictionary, of all the words it met on the
                way. Then, a vector for each abstract is a vector with
                the same size as the corpus dictionary where each word
                has been replaced by the count of how many times it
                appears in this specific abstract. </small>
            </p>
            
            <h4> Mostly zeros then ? </h4>
            <p class="lead"> <small> Yes basically, expect for the
            words that appear in that abstract. </small>
            </p>
            
            <h4> And are there only 500 different words in the whole
            abstract corpus of AGU ? </h4>
            <p class="lead"> <small> Well .... No. It is more like
                15739. It then uses a technique called <a href="https://en.wikipedia.org/wiki/Latent_semantic_analysis">Latent Semantic
                Analysis (LSA)</a> to shrink the representation to 500
                dimensions.  It is a common method in information
                retrieval to reduce the dimension of the
                representation space. It aims to reduce the dimensions
                while keeping as much information possible present in
                the higher dimensional space by identifying deep
                semantic pattern in the corpus.</small>
            </p>

            <h4> An example ? </h4>
            <p class="lead"> <small> Well, for instance, the token
            global and warming are more likely to occur together.
            Combining these two dimensions to only one reduces the
            dimensional space without much losses of information. For
            more details, check-out this blog post I wrote about
                <a href="http://cthorey.github.io./AGU_Part3/">the
                recommendation engine</a>  </small>
            </p>

            <h4> Ok. So, at the end, each abstract is a point in this
            500-dimension space, whatever that looks like, right ?</h4>
            <p class="lead"> <small> Yes, a vector to be exact. And,
            your request, be it a combination of keywords or an
            abstract, is also transformed to live in this
            representation space.</small>
            </p>

            <h4> And so, what is this similarity measure which allows
            the engine to find only relevant contributions ? </h4>
            <p class="lead"> <small> It is the cosine similarity
                between your request vector against all the abstract
                vectors. See it as the angle your request vector makes
                with all the contributions. It is one when the
                contribution points in the same direction as your
                request, i.e. they share a lot in term of semantics and
                topics and -1 otherwise.</small>
            </p>

            <h4> Then, for a specific request, the engine only returns
            those that are close to 1? </h4>
            <p class="lead"> <small> Right. Larger than 0.3 exactly.</small>
            </p>
            
            <h4> And how do you know it works? </h4>
            <p class="lead"> <small> First, It gives highly relevant
                results for my two contributions and for those of my
                colleagues in Paris. But may be you like something more
                qualitative.  Take a look at the figure below. It gives
                you a sense of the structure of the 500-dimensional
                space the engine has designed. In particular, abstracts
                close up there (whatever that means in 500 dimensions)
                are close on the figure.
            </small>
            </p>

            <div class="text-center">
                <figure>
                    <a href="https://plot.ly/~clement.thorey/56/t-sne-of-the-500-lsa-embedding/"
                       target="_blank"
                       title="t-sne of the 500 LSA embedding"
                       style="display: block; text-align: center;">
                        <img src="{{url_for('static',filename='images/tsne_LSA_500_geocolab.png')}}"
                             alt="t-sne of the 500 LSA embedding"
                             style="max-width: 100%;width: 800px;"
                             width="800" /></a>
                </figure>
                <figcaption> Click on the figure to get its interactive counterpart.</figcaption>
            </div>
            
            <h4> Nice, it is able to grab the section/session
            structure of the conference ! </h4>
            <p class="lead"> <small> Yes, but, may be more
                importantly, it is also able to find relevant
                contributions from totally different sections and
                surely, will widens the field of interesting
                contributions you will see at AGU next year. 
            </small>
            </p>
            
            <h4> Why did you do that in the first place? </h4>
            <p class="lead"> <small> Mostly, I wanted to learn about
                natural language processing techniques, relational
                databases and build my own web application.  Trying to
                navigate through the AGU conference last year, I
                figured it could be a good idea to use the abstract
                content of the conference and try to build something
                on top of it.
            </p></small>
        </div>

{% endblock %}

{% block late_js %}
    <script text="type/javascript">
     $(document).ready(function() {
         dropdownMenuNav()
     });
    </script>

{% endblock %}

